{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial Env: Defining Optimization Environments for Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `function_interface.ipynb` illustrated how one can create new test functions for evaluating or training algorithms. However, in many practical settings, we don't directly access the function itself during optimization. The optimized function is wrapped around in an arbitrary complex environment that we iteratively poll for evaluation of input queries and receiving its feedback. In essence, the optimized function is part of a larger complex environment. Usually, optimization algorithms like: Bandits, or Evolutionary Algorithms, pre-process alot of this complexity away for the agent. As ambition grows to more complex environments, manual pre-processing can become unsustainable, and more sophisticated methods might be needed.\n",
    "\n",
    "This notebook illustrates a number of Environments we have implemented using the `dm-env`/ `jumanji` Environment API, that wraps complexity around a `Function` instance to reflect the complexities of real-world Black-Box Optimization. These environments are intended to benchmark and test existing or new Black-Box Optimization algorithms in more than just a Bandit setting.\n",
    "\n",
    "This optional `env` sub-module to `bbox` can be installed with the command:\n",
    "```bash\n",
    "python -m pip install bbox[env]\n",
    "```\n",
    "Which will jointly install `jumanji` along with other dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-06-08T15:12:11.127942698Z",
     "start_time": "2023-06-08T15:12:10.751594715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bandit(function=PartialGaussianProcessPrior,in_spec=BoundedArray(name=inputs,shape=(2,),dtype=float32,minimum=-1.0,maximum=1.0),out_spec=Array(name=outputs,shape=(),dtype=float32),use_reward_as_observation=True)\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "from jax import numpy as jnp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bbox import procgen as px\n",
    "from bbox import env\n",
    "\n",
    "\n",
    "key = jax.random.PRNGKey(123)\n",
    "\n",
    "\n",
    "# Environment instantiation closely follows the core Function API.\n",
    "rbf = lambda a, b: jnp.exp(-0.5 * jnp.sum(jnp.square(a - b)))\n",
    "my_env = env.as_bandit(\n",
    "    base=px.real.GaussianProcessPrior.partial(kernel=rbf, resolution=10),\n",
    "    wrappers=None,\n",
    "    dummy_x=jnp.zeros(2)\n",
    ")\n",
    "\n",
    "print(repr(my_env))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown below, the Environment API follows that of `dm-env`/ `jumanji` and enables a conventional agent-environment loop for Reinforcement Learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T15:12:11.276048867Z",
     "start_time": "2023-06-08T15:12:10.848318587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: [ 0.4381199  -0.10669184]\n",
      "timestep: TimeStep(step_type=1.0, reward=0.10252925753593445, discount=1.0, observation=0.10252925753593445, extras={})\n"
     ]
    }
   ],
   "source": [
    "from jit_env._core import TimeStep\n",
    "from jit_env import Action\n",
    "\n",
    "\n",
    "def run_experiment(_key, _env) -> list[(Action, TimeStep)]:\n",
    "    state, step = _env.reset(_key)\n",
    "\n",
    "    steps = [(jnp.zeros(2), step)]\n",
    "    for _ in range(10):\n",
    "        _key, key_policy = jax.random.split(_key)\n",
    "\n",
    "        # Agent-Environment Interaction\n",
    "        action = jax.random.uniform(key_policy, (2,), minval=-1, maxval=1)\n",
    "        state, step = _env.step(state, action)\n",
    "\n",
    "        steps.append((action, step))\n",
    "        \n",
    "    return steps\n",
    "    \n",
    "    \n",
    "data = run_experiment(key, my_env)\n",
    "\n",
    "print('action:', data[-1][0])\n",
    "print('timestep:', jax.tree_map(float, data[-1][1]))\n",
    "\n",
    "# >> action: [ 0.4381199  -0.10669184]\n",
    "# >> timestep: TimeStep(step_type=DeviceArray(1, dtype=int8), reward=DeviceArray(-0.17889404, dtype=float32), \n",
    "#  discount=DeviceArray(1., dtype=float32), observation=DeviceArray(-0.17889404, dtype=float32), extras={})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment state follows a simple layout that allows the branching of a Random Key, as required by the `Generic[State]` protocol from `jumanji.State` as well as tracking the base system time count and wrapper + base data. New Wrappers should not modify `EnvState` explicitly, but can implement their own internal state datastructure and registering that in the `data` attribute of `EnvState` through the class instance `hash` or `repr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T15:12:11.277088465Z",
     "start_time": "2023-06-08T15:12:11.270296104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Unwrapped Environment State: Bandit(function=PartialGaussianProcessPrior,in_spec=BoundedArray(name=inputs,shape=(2,),dtype=float32,minimum=-1.0,maximum=1.0),out_spec=Array(name=outputs,shape=(),dtype=float32),use_reward_as_observation=True)\n",
      "key (2,)\n",
      "time ()\n",
      "data <class 'dict'>\n",
      "\n",
      "Bandit(function=PartialGaussianProcessPrior) FunctionState(params={'PartialGaussianProcessPrior': {'bases': (10,), 'shift': (10, 2)}}, state=None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Example Unwrapped Environment State:', repr(my_env))\n",
    "state, step = my_env.reset(key)\n",
    "\n",
    "for k, v in state.items():\n",
    "    if k == 'data':\n",
    "        print(k, type(v), end='\\n\\n')\n",
    "        for wk, wv in v.items():\n",
    "            print(wk, jax.tree_map(jnp.shape, wv), end='\\n\\n')\n",
    "    else: \n",
    "        print(k, jax.tree_map(jnp.shape, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T15:12:11.671693847Z",
     "start_time": "2023-06-08T15:12:11.280424288Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'bbox.env.delay' has no attribute 'BatchDelay'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m batched_env \u001B[38;5;241m=\u001B[39m \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdelay\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mBatchDelay\u001B[49m(my_env, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExample wrapped Environment State:\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28mrepr\u001B[39m(batched_env))\n\u001B[1;32m      4\u001B[0m state, step \u001B[38;5;241m=\u001B[39m batched_env\u001B[38;5;241m.\u001B[39mreset(key)\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'bbox.env.delay' has no attribute 'BatchDelay'"
     ]
    }
   ],
   "source": [
    "batched_env = env.delay.BatchDelay(my_env, batch_size=2)\n",
    "\n",
    "print('Example wrapped Environment State:', repr(batched_env))\n",
    "state, step = batched_env.reset(key)\n",
    "\n",
    "for k, v in state.items():\n",
    "    if k == 'data':\n",
    "        print(k, type(v), end='\\n\\n')\n",
    "        for wk, wv in v.items():\n",
    "            print(wk, jax.tree_map(jnp.shape, wv), end='\\n\\n')\n",
    "    else: \n",
    "        print(k, jax.tree_map(jnp.shape, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the BatchDelay wrapper registers a `DelayedState` data object within `state.data` under its `__repr__`. Even though the key is recursively defined, storing all data in a flat dictionary allows subsequent wrapper more direct access to the state data. It also ensures compatibility of unwrapped environments with the wrapped environment state, as they can simply ignore the unused entries in the `state.data` dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Delay Wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation for the `Delay` Wrappers functions through wrapping any conventional `Environment` as a base and induce environment feedback asynchronicity through an `EventBuffer`. As shown before, the `BatchDelay` Wrapper stores the `DelayedState` datastructure with the `buffer` attribute. The core philosophy around this Wrapper Type is to restrict the agent from having direct access to the underlying optimized function and only allow it to communicate through the `EventBuffer` proxy. At any time `t` the agent can push an action to the wrapped environment, and the environment/ wrapper's dynamics will govern when the agent will receive feedback by postponing observations within the `EventBuffer`. \n",
    "\n",
    "Typically, the Wrapper directly evaluates the given query, and writes the results to `EventBuffer` before subsequently reading this tape at the current `state.time`. Although this resembles popping a Buffer in a FIFO manner, like a Queue, note that empty events are typically not time-skipped. Although, this is still possible with the `AwaitEvent` Wrapper, as we'll show later on.\n",
    "\n",
    "##### Agent-Environment Dimensionality\n",
    "To preserve static Array shapes within a Jax compatible Environment, the agent-environment dimensionality can change dependent on which Delay Type is instantiated. Typically, the observations of the original Environment are transformed into shape: `(buffer_size, *original_shape)` batches of observations.\n",
    "\n",
    "##### TimeStep.Extras\n",
    "The environment interface returns at every call to `step` or `reset` both an Environment `State` and a `TimeStep`. The `TimeStep` structure contains the observation/ feedback to the agent. On top of that, this struct contains an `extras` dictionary with meta-data from the underlying Environments. Typically this attribute is empty, and the agent does not have direct access to it. However, for logging, or subsequent transforms in the form of other (`Delay`) Wrappers, this meta-data can be helpful. For example, when updating a resource budget, or when monitorring time statistics, we might not want this information to be delayed. \n",
    "\n",
    "The Delay environments include two additional datastructures within `TimeStep.extras`. \n",
    " 1. The Unwrapped Environment's unmodified TimeStep.\n",
    " 2. The explicit readout from the Delay's `EventBuffer` in the form of a `BufferInfo` structure.\n",
    " \n",
    "The unmodified TimeStep can be utilized for monitorring purposes, whereas the `BufferInfo` can be utilized to exactly re-identify which delayed action has now received feedback and whether the given observation actually contains an event or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_env = env.delay.BatchDelay(my_env, batch_size=2)\n",
    "timed_batched_env = env.wrappers.TimeLimit(batched_env, max_episode_steps=10)\n",
    "\n",
    "# The class __repr__ recursively tracks how base gets wrapped.\n",
    "print(\"BatchEnv Hierarchy:\", repr(batched_env))\n",
    "print(\"TimedEnv Hierarchy:\", repr(timed_batched_env))\n",
    "print()\n",
    "\n",
    "print('Canonical Observation shape:', my_env.observation_spec())\n",
    "print('Batch Observation shape:', batched_env.observation_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = run_experiment(key, timed_batched_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the new datastructures\n",
    "act_ref, step_ref = data[-2]\n",
    "\n",
    "# The action is unchanged\n",
    "print('action:', act_ref)\n",
    "# >> action: [ 0.4381199  -0.10669184]\n",
    "\n",
    "# Remove the extras dictionary for readability.\n",
    "extras = step_ref.__dict__.pop('extras')\n",
    "\n",
    "# The observation is now a vector of batch-size = 2\n",
    "print('timestep', step_ref)\n",
    "# >> timestep TimeStep(step_type=DeviceArray(2, dtype=int8), reward=DeviceArray(0., dtype=float32), \n",
    "#  discount=DeviceArray(0., dtype=float32), observation=DeviceArray([0., 0.], dtype=float32), extras=None)\n",
    "\n",
    "step_ref.__dict__['extras'] = extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in extras.items():\n",
    "    print(k)\n",
    "    print('>', v)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BufferInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `BufferInfo` object contains meta-data for the read-event within the Delay Wrapper. It tracks: the actual read-data, the Wrapper's internal time (which can deviate from `state.time`), the number of events that are contained within the buffer, and the ID of the system (default None; integer type in scheduled systems)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_info = extras['/'.join((repr(batched_env), env.BufferInfo.__name__))]\n",
    "\n",
    "readout: env.EventBuffer = buffer_info.__dict__.pop('readout')\n",
    "\n",
    "print(\"BufferInfo Misc. Information:\", buffer_info.__dict__)\n",
    "print()\n",
    "\n",
    "buffer_info.__dict__['readout'] = readout\n",
    "print(readout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursive Delays: IID Delayed Batches\n",
    "\n",
    "The different types of Delay Environment Wrappers can be freely composed recursively, as long as your computer memory allows.\n",
    "\n",
    "This requires some careful calculations! For example, the SensoryDelay wrapper maintains a buffer of `buffer_size * buffer_size * shapes`, the BatchDelay maintains a buffer of `batch_size * shapes`. In total this recursion induces an effective buffer of `buffer_size * buffer_size * batch_size * shapes`. Which in this example incurs a buffer size of `200 * shapes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_delay_env = env.delay.SensoryDelay(\n",
    "    batched_env, delay_process=lambda *_: 0, buffer_size=10, synchronize=False)\n",
    "\n",
    "delay_env = env.delay.SensoryDelay(\n",
    "    batched_env, delay_process=lambda *_: 1, buffer_size=10, synchronize=False)\n",
    "\n",
    "print(\"DelayedEnv Hierarchy:\", repr(null_delay_env))\n",
    "print(\"DelayedEnv Hierarchy:\", repr(delay_env))\n",
    "\n",
    "batched_data = run_experiment(key, batched_env)\n",
    "null_delay_data = run_experiment(key, null_delay_env)\n",
    "delay_data = run_experiment(key, delay_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Reward Readout/ Event Times:\")\n",
    "print(\"\\tBatched \\tNo Delay\\tDelay\")\n",
    "\n",
    "for i, (a, b, c) in enumerate(zip(batched_data, null_delay_data, delay_data)):\n",
    "    print(i, f'\\t{int(a[1].reward != 0)}\\t\\t{int(b[1].reward != 0)}\\t\\t{int(c[1].reward != 0)}'.replace('0', '-'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synchronized Delays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Delay Types allow for the keyword argument `synchronize`, this is default behaviour for `BatchDelay`. If a Delay Wrapper wraps another Delay Wrapper, this allows the outer wrapper to check whether its current TimeStep is delayed or not. If so, by setting `synchronize=True` it will not record the observation to the `EventBuffer` and it will not pop the latest event from the Buffer to read. This is useful for reducing the memory footprint of the buffer as it prevents writing empty events, as a result, one can use smaller buffer sizes.\n",
    "\n",
    "For example, this is useful when wrapping: `BatchDelay(SensoryDelay(env))`. The BatchDelay will not update the batch-buffer, until the received observation can be considered not null. In the cells below we show how this affects the event-timings of the previous cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_delay_env = env.delay.SensoryDelay(\n",
    "    batched_env, delay_process=lambda *_: 0, buffer_size=10, synchronize=True)\n",
    "\n",
    "delay_env = env.delay.SensoryDelay(\n",
    "    batched_env, delay_process=lambda *_: 1, buffer_size=10, synchronize=True)\n",
    "\n",
    "print(\"DelayedEnv Hierarchy:\", repr(null_delay_env))\n",
    "print(\"DelayedEnv Hierarchy:\", repr(delay_env))\n",
    "\n",
    "batched_data = run_experiment(key, batched_env)\n",
    "null_delay_data = run_experiment(key, null_delay_env)\n",
    "delay_data = run_experiment(key, delay_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Reward Readout/ Event Times:\")\n",
    "print(\"\\tBatched \\tNo Delay\\tDelay\")\n",
    "\n",
    "for i, (a, b, c) in enumerate(zip(batched_data, null_delay_data, delay_data)):\n",
    "    print(i, f'\\t{int(a[1].reward != 0)}\\t\\t{int(b[1].reward != 0)}\\t\\t{int(c[1].reward != 0)}'.replace('0', '-'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the delay of `delay_env` is always `1`, which is uneven, the synchronization prevents a read-event from occuring until the feedback from the underlying event is also non-empty. In the previous example with `synchronize=False` the events of `delay_env` occured at uneven time-steps (where the underlying BatchDelay Wrapper did not yield an event) whereas in the above example `synchronize=True` the events occur at even time-steps (synchronously with any non-null event from BatchDelay)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Optimization and System Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple instances of the EventBuffer can be maintained by certain Wrappers, the agent must then also consider the *throughput* of its actions by scheduling its actions to some system of choice. This also allows systems to terminate asynchronously through a `TimeLimit` or `BudgetConstraint` wrapper, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### EventAwaiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax import numpy as jnp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bbox import procgen as px\n",
    "from bbox import env\n",
    "\n",
    "\n",
    "key = jax.random.PRNGKey(123)\n",
    "\n",
    "\n",
    "# Environment instantiation closely follows the core Function API.\n",
    "rbf = lambda a, b: jnp.exp(-0.5 * jnp.sum(jnp.square(a - b)))\n",
    "my_env = env.as_bandit(\n",
    "    base=px.real.GaussianProcessPrior.partial(kernel=rbf, resolution=10),\n",
    "    wrappers=None,\n",
    "    dummy_x=jnp.zeros(2)\n",
    ")\n",
    "\n",
    "print(repr(my_env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bbox.env import ScheduledAction\n",
    "\n",
    "\n",
    "delay_env = env.delay.SensoryDelay(my_env, delay_process=lambda *_: 1, buffer_size=5)\n",
    "await_env = env.scheduling.FlushDelay(delay_env, max_steps=10)\n",
    "\n",
    "print('Canonical Action:', delay_env.action_spec().generate_value())\n",
    "print()\n",
    "print('AwaitEvent Wrapper Action:', await_env.action_spec().generate_value())\n",
    "\n",
    "\n",
    "state, step = await_env.reset(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, step = await_env.reset(key)\n",
    "\n",
    "for _ in range(4):\n",
    "    state, step = await_env.step(state, ScheduledAction(action=jnp.ones(2), system_id=0))\n",
    "    print(state.time, step.reward)\n",
    "    \n",
    "    state, step = await_env.step(state, ScheduledAction(action=jnp.ones(2), system_id=1))\n",
    "    print(state.time, step.reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, step = await_env.reset(key)\n",
    "\n",
    "for _ in range(4):\n",
    "    state, step = await_env.step(state, ScheduledAction(action=jnp.ones(2), system_id=0))\n",
    "    \n",
    "    print(state.time, step.reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Time/ Budget Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Batch Delay example, we already showed how to instantiate a TimeLimit on an Environment. Opposed to conventional implementations, our TimeLimit wrapper is sensitive to the ordering of the Wrapping, as it tracks the number of calls to the environment itself. This behaviour is optional and can be opted for using `track_self=True`, if one wants to use the environment `EnvState.time` for the time-budget then you should use `track_self=False`. This is useful for System Scheduling Environments, where the Environment can have partially terminated sub-environments without terminating itself. The cell below illustrates this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in [True, False]:\n",
    "    timed_env = env.wrappers.TimeLimit(my_env, max_episode_steps=2, track_self=b, terminate=True)\n",
    "    \n",
    "    delay_env = env.industrial.SensoryDelay(timed_env, delay_process=lambda b: 1, buffer_size=5)\n",
    "    await_env = env.industrial.EventAwaiter(delay_env)\n",
    "    \n",
    "    state, step = await_env.reset(key)\n",
    "\n",
    "    print(f\"Timed track_self: {b}\")\n",
    "    for _ in range(3):\n",
    "        state, step = await_env.step(state, ScheduledAction(action=jnp.ones(2), system_id=0))\n",
    "        print(f't_outer={state.time}, t_wrapper={state.data[repr(timed_env)].cumulative} done={step.last()}, r={step.reward:.4f}')\n",
    "        \n",
    "        state, step = await_env.step(state, ScheduledAction(action=jnp.ones(2), system_id=1))\n",
    "        print(f't_outer={state.time}, t_wrapper={state.data[repr(timed_env)].cumulative} done={step.last()}, r={step.reward:.4f}')\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bakery: Combining all of the Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
